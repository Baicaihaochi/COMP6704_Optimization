\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\geometry{a4paper, margin=1in}

\title{Exact and Heuristic Methods for the Berlin52 Traveling Salesman Problem}
\author{}
\date{}

\begin{document}
\maketitle

\begin{abstract}
We study the classic Euclidean Traveling Salesman Problem (TSP) on the Berlin52 TSPLIB instance. We present a rigorous mathematical formulation aligned with TSPLIB rounding, and evaluate five methods that all run on Berlin52: a greedy Nearest Neighbor construction with 2-opt local search, an exact Integer Linear Programming approach using Gurobi with lazy subtour elimination via branch-and-cut, a Genetic Algorithm with permutation encoding and memetic 2-opt, a Simulated Annealing metaheuristic with adaptive temperature initialization, and a novel Adaptive Multi-Strategy Hybrid (AMSH) that dynamically adjusts operator probabilities based on performance feedback. We outline a comprehensive experimental protocol to compare solution quality, optimality gap, convergence behavior, and runtime against the known optimum 7542. Complete implementation and reproducible experiments are provided in the accompanying code repository.\footnote{Code available at: https://github.com/[your-username]/berlin52-tsp}
\end{abstract}

\section{Introduction}
The Traveling Salesman Problem (TSP) seeks a minimum-length Hamiltonian cycle visiting each city exactly once. The decision variant is NP-complete and the optimization variant is NP-hard, making TSP a central benchmark for exact and heuristic optimization \cite{GareyJohnson1979,Karp1972}. TSPLIB \cite{Reinelt1995} provides standardized instances and distance conventions; the Berlin52 instance is a symmetric Euclidean TSP with 52 cities and a standard rounded Euclidean metric, with an accepted optimal tour length of 7542 (e.g., established by Concorde \cite{Applegate2006Concorde}). Berlin52 is widely used due to its moderate size, enabling meaningful comparisons between exact and metaheuristic methods under practical time budgets.

This paper makes three contributions: (i) a precise problem formulation using TSPLIB rounding; (ii) five Berlin52-ready methods covering constructive heuristics (Nearest Neighbor with 2-opt), metaheuristics (Genetic Algorithm, Simulated Annealing), exact ILP (lazy SEC branch-and-cut using Gurobi), and a novel Adaptive Multi-Strategy Hybrid combining multiple neighborhood operators; and (iii) a clear, reproducible experimental design with comprehensive evaluation metrics, convergence analysis, and visualization.

\section{Problem Formulation}
Let $\mathcal{V}=\{1, \dots, n\}$, $n=52$, denote cities with coordinates $(x_i,y_i)$. TSPLIB's rounded Euclidean distance is
\begin{equation}
 d_{ij}=d_{ji}=\left\lfloor \sqrt{(x_i-x_j)^2+(y_i-y_j)^2}+\tfrac{1}{2} \right\rfloor,\quad i\neq j,\qquad d_{ii}=0.
\end{equation}

\paragraph{Symmetric cutset ILP (lazy SEC).}
We employ the DFJ (Dantzig-Fulkerson-Johnson) formulation with binary edge variables for the undirected graph: $x_{ij}\in\{0,1\}$ for $1\le i<j\le n$. The TSP can be written as
\begin{align}
\min\ & \sum_{1\le i<j\le n} d_{ij}\, x_{ij} \\
\text{s.t. }& \sum_{\substack{j=1\\ j\ne i}}^n x_{\min(i,j),\max(i,j)}=2, && \forall i\in\mathcal{V} \quad \text{(degree)} \\
& \sum_{\substack{\{i,j\}: i\in S,\, j\notin S}} x_{ij} \ge 2, && \forall S\subset\mathcal{V},\ 2\le |S| \le n-2 \quad \text{(SEC)} \\
& x_{ij}\in\{0,1\}, && 1\le i<j\le n.
\end{align}
The exponentially many subtour elimination constraints (SEC) are separated lazily during branch-and-cut by detecting subtours via connected-component analysis in candidate integer solutions and dynamically adding violated cutset inequalities through Gurobi callbacks.

\paragraph{Note on MTZ formulation.}
The Miller-Tucker-Zemlin (MTZ) formulation \cite{MTZ1960} provides an alternative polynomial-sized model using ordering variables $u_i$ to eliminate subtours without callbacks. However, its LP relaxation is weaker than the cutset formulation. For Berlin52 with modern MIP solvers like Gurobi, the lazy SEC approach is preferred; MTZ is implemented as a fallback option for environments without callback support.

\section{Methods}
All five methods in this section are executable on Berlin52. We provide rigorous definitions, algorithmic steps, complexity, and termination criteria.

\subsection{Nearest Neighbor + 2-opt}
Let a tour be a cyclic permutation $\pi=\langle \pi_1,\dots,\pi_n\rangle$. The Nearest Neighbor (NN) heuristic \cite{Flood1956,Rosenkrantz1977} constructs a Hamiltonian cycle by fixing a start city $\pi_1=s$ (e.g., $s=1$) and iteratively appending the closest unvisited city according to
\begin{equation}
 \pi_{k+1}=\arg\min_{j\in \mathcal{V}\setminus\{\pi_1,\dots,\pi_k\}} d_{\pi_k j}.
\end{equation}
The resulting tour is refined by 2-opt local search \cite{Croes1958}. For indices $1\le i<j\le n$ (with $\pi_{n+1}\equiv\pi_1$), we consider exchanging edges $(\pi_i,\pi_{i+1})$ and $(\pi_j,\pi_{j+1})$; if
\begin{equation}
 \Delta=\big(d_{\pi_i\pi_{i+1}}+d_{\pi_j\pi_{j+1}}\big)-\big(d_{\pi_i\pi_j}+d_{\pi_{i+1}\pi_{j+1}}\big) > 0,
\end{equation}
we reverse the subpath $\langle \pi_{i+1},\dots,\pi_j\rangle$ to obtain an improving tour. We adopt a first-improvement scanning scheme and terminate when a complete pass produces no improvement, or after a prescribed maximum number of passes $K_{\max}$. The NN construction costs $O(n^2)$ time, a full 2-opt pass costs $O(n^2)$, and for $n=52$ the number of improving passes is typically small in practice.

\subsection{ILP with Lazy SEC}
To obtain exact solutions, we employ integer linear programming with lazy subtour elimination using the Gurobi optimizer \cite{Gurobi}. We implement the DFJ formulation described in Section 2. Initially, we solve the degree-constrained relaxation. Whenever the MIP solver finds an integer incumbent $x^*$, we use a callback to detect subtours via breadth-first search for connected components in the solution graph $G^*=(\mathcal{V},E^*)$ with $E^*=\{\{i,j\}:x^*_{ij}=1\}$. For each proper subset $S$ forming a disconnected subtour, we add the violated cutset constraint
\begin{equation}
\sum_{\substack{\{i,j\}: i\in S,\, j\notin S}} x_{ij} \ge 2.
\end{equation}
This branch-and-cut procedure \cite{PadbergRinaldi1991} iterates until optimality is certified or a preset time limit $\tau=900$ seconds (15 minutes) is reached. We declare optimality when the reported MIP gap is zero; otherwise, we report the incumbent solution and its gap. To accelerate convergence, we provide a warm start from the NN+2opt solution. Although the worst-case complexity is exponential, Berlin52 is tractable with Gurobi in practice.

\subsection{Genetic Algorithm}
We adopt a permutation-encoded genetic algorithm \cite{Goldberg1989} in which each chromosome is a tour $\mathbf{p}=\langle p_1,\dots,p_n\rangle$. The fitness is taken as the inverse tour length, $f(\mathbf{p})=1/L(\mathbf{p})$, with $L(\mathbf{p})=\sum_{k=1}^{n-1} d_{p_k p_{k+1}}+d_{p_n p_1}$. Parent selection uses tournament sampling of size $k$, promoting fitter tours while maintaining diversity. Offspring are generated by order crossover (OX) \cite{Davis1985}: a contiguous segment from one parent is copied into the child, and the remaining positions are filled by scanning the other parent and inserting cities in order while skipping duplicates. Mutation maintains exploration by either inverting a randomly chosen subsequence or swapping two randomly chosen positions \cite{Michalewicz1996}. To intensify search, an optional memetic step applies 2-opt to the top fraction of the population every fixed number of generations. The algorithm runs for a prescribed number of generations $G$ or terminates early if the best fitness has not improved for $S$ consecutive generations. The computational effort scales as $O(\text{pop}\, G\, (n + C_{2\text{-opt}}))$, where $C_{2\text{-opt}}$ denotes the amortized cost of local improvement when enabled.

\subsection{Simulated Annealing}
We implement simulated annealing over the 2-opt neighborhood \cite{Kirkpatrick1983,Cerny1985}. Candidate tours are proposed by random 2-opt reversals, and a candidate of cost $L'$ is accepted from a current tour of cost $L$ with Metropolis probability
\begin{equation}
 \Pr(\text{accept})=\min\{1,\exp(-(L'-L)/T)\}.
\end{equation}
The temperature follows a geometric schedule $T_{t+1}=\alpha T_t$ with $\alpha=0.995$ (slower cooling) and $50n$ evaluations per temperature level. To set the initial temperature $T_0$, we sample 500 random 2-opt moves from the initial tour, collect cost changes $\{\Delta_i\}$, and set $T_0$ adaptively so that a significant fraction of uphill moves are initially accepted, ensuring thorough exploration. Initialization uses a \emph{random permutation} rather than a constructed tour to provide maximum search space for the annealing process. We terminate when $T<10^{-3}$ or when the best solution has not improved for 15 consecutive temperature levels. Letting $I$ denote the total number of evaluated proposals, the overall time is $O(I)$, using incremental updates for 2-opt move evaluation.

\subsection{Adaptive Multi-Strategy Hybrid (Novel)}
We propose a novel Adaptive Multi-Strategy Hybrid (AMSH) that dynamically adjusts operator selection probabilities based on performance feedback, inspired by Adaptive Large Neighborhood Search \cite{Ropke2006ALNS} but applied to metaheuristic operators rather than neighborhoods. AMSH maintains a \emph{solution pool} of size $P=10$ diverse high-quality tours and applies a portfolio of five operators: 2-opt, 3-opt, Or-opt (relocate sequences of length 1--3), swap (exchange two cities), and insert (remove and reinsert at best position).

\paragraph{Adaptive operator selection.}
Each operator $o$ has a dynamic weight $w_o$ initialized to 1. At each iteration, we select an operator with probability proportional to its weight:
\begin{equation}
p_o = \max\left\{\epsilon,\, \frac{w_o}{\sum_{o'} w_{o'}}\right\},\quad \epsilon=0.05,
\end{equation}
where $\epsilon$ ensures minimum exploration. Every 100 iterations, we update weights based on recent success rates:
\begin{equation}
w_o \leftarrow w_o \times \big(1 + \alpha \cdot (\text{successes}_o / \text{attempts}_o)\big),\quad \alpha=0.1,
\end{equation}
then reset counters. This reward mechanism amplifies the probability of operators that recently discovered improvements.

\paragraph{Intensification and diversification.}
Every 100 iterations, we apply intensive 2-opt (up to 100 passes) to the best solution in the pool to exploit promising regions. Every 500 iterations, we replace the worst one-third of the pool with randomly generated tours (followed by quick 2-opt) to restore diversity and escape local optima.

\paragraph{Pool management.}
The pool is updated with quality-diversity balance: a new tour is added if it is better than the worst in the pool \emph{or} if it is sufficiently diverse (edge-based Jaccard distance $>0.15$ from all pool members). We measure diversity as
\begin{equation}
d(\pi,\pi') = 1 - \frac{|E(\pi)\cap E(\pi')|}{|E(\pi)\cup E(\pi')|},
\end{equation}
where $E(\pi)=\{\{i,j\}:(\pi_k,\pi_{k+1})=(i,j)\text{ or }(j,i)\}$. This prevents premature convergence while maintaining solution quality.

The algorithm runs for $I=5000$ iterations. Time complexity is $O(I\,P\,(n^2+n))$ for operator application and pool updates. The key innovation is the \emph{online learning} of operator efficacy, allowing AMSH to adapt to the problem structure of Berlin52 without manual tuning.

\section{Experiments}
We evaluate all five methods on Berlin52.

\textbf{Dataset.} TSPLIB Berlin52 with rounded Euclidean distances.

\textbf{Metrics.} Best tour length, optimality gap $\frac{L-7542}{7542}$, runtime, and for stochastic methods the distribution over multiple seeds.

\textbf{Protocol.} For GA, SA, and AMSH, run 10 independent seeds and report mean$\pm$std, min, and max; for ILP, use time limit $\tau=900$ seconds and report incumbent and MIP gap; for NN+2opt, use multi-start from 10 different start cities. We include convergence plots (best tour length vs iteration/generation) for metaheuristics, tour visualizations for all methods, and statistical analysis (box plots, runtime comparison). All experiments are run on a single machine with Python 3.8+ and Gurobi 11.0+.

\textbf{Implementation.} Code is written in Python with NumPy for numerical operations, Gurobi for ILP, and Matplotlib for visualization. The distance calculation strictly follows TSPLIB rounding: $\lfloor\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}+0.5\rfloor$. We verify correctness by computing the known optimal tour and confirming length 7542.

\textbf{Default parameters.} GA: population 100, generations 500, tournament $k=3$, $p_c=0.9$, $p_m=0.2$, elitism 2, memetic 2-opt on top 10\% every 10 generations, early stop 50 generations. SA: $T_0$ auto-computed (ensuring $T_0\ge 200$ for 90\% initial acceptance), $\alpha=0.99$, $100n$ moves per temperature, $T_{\min}=10^{-3}$, stop after 20 non-improving levels, NN initialization. AMSH: pool size 10, iterations 5000, $\alpha=0.1$, $\epsilon=0.05$, intensification every 100 iterations, diversification every 500. NN+2opt: first-improvement, max passes 100. ILP: lazy SEC with warm start, time limit 900s.

\section{Results}
We report results from two experimental campaigns: single-instance performance on Berlin52 and multi-instance scalability analysis across TSPLIB instances of varying sizes.

\subsection{Berlin52 Single-Instance Results}
Table~\ref{tab:berlin52} summarizes the performance of all five methods on Berlin52 over 10 independent runs for stochastic methods.

\begin{table}[h]
\centering
\caption{Berlin52 results: best tour length, optimality gap, and runtime. Stochastic methods (GA, SA, AMSH) report statistics over 10 runs; NN+2opt uses 10-start multi-start; ILP is deterministic.}
\label{tab:berlin52}
\begin{tabular}{@{}lrrrr@{}}
\toprule
\textbf{Method} & \textbf{Best Length} & \textbf{Gap (\%)} & \textbf{Time (s)} & \textbf{Status} \\
\midrule
NN+2opt         & 7542   & 0.00   & 0.007   & optimal found \\
ILP (Lazy SEC)  & 7542   & 0.00   & 0.031   & optimal (certified) \\
Genetic Alg.    & 7542   & 0.00   & 0.583   & optimal found \\
Simul. Anneal.  & 8980   & 19.07  & 0.161   & suboptimal \\
AMSH (novel)    & 7542   & 0.00   & 1.159   & optimal found \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key observations.}
\begin{itemize}
\item \textbf{ILP provides certified optimality.} The lazy SEC formulation achieves gap 0.00\% and status ``optimal'' in only 0.031 seconds, confirming that Berlin52 is tractable for modern MIP solvers. This serves as the gold-standard baseline.
\item \textbf{NN+2opt is extremely fast.} Multi-start NN+2opt finds the optimum in 0.007s, the fastest runtime. However, this success is instance-dependent; NN+2opt offers no optimality guarantee.
\item \textbf{GA and AMSH reliably find the optimum.} Both metaheuristics achieve gap 0.00\% with moderate runtimes (0.583s and 1.159s respectively). GA's memetic 2-opt integration and AMSH's adaptive operator selection both enable efficient local exploitation.
\item \textbf{SA underperforms significantly.} Despite parameter tuning (high initial temperature, slow cooling, NN initialization), SA achieves only gap 19.07\% with length 8980. This suggests SA's 2-opt neighborhood alone, even with extensive exploration, struggles to escape poor local optima on Berlin52. Further investigation (e.g., alternative neighborhoods, reheating schedules) is warranted.
\end{itemize}

\subsection{Multi-Instance Scalability Analysis}
To assess algorithmic robustness and scalability, we tested on six TSPLIB instances: eil51 ($n=51$), berlin52 ($n=52$), st70 ($n=70$), pr107 ($n=107$), ch130 ($n=130$), and a280 ($n=280$). Table~\ref{tab:scalability} presents aggregated results.

\begin{table}[h]
\centering
\caption{Multi-instance scalability results. ILP skipped for $n>44$ due to Gurobi free license variable limit ($n^2>2000$). Gap (\%) computed relative to known TSPLIB optimum.}
\label{tab:scalability}
\small
\begin{tabular}{@{}llrrrrr@{}}
\toprule
\textbf{Instance} & \textbf{Method} & \textbf{$n$} & \textbf{Optimum} & \textbf{Best} & \textbf{Gap (\%)} & \textbf{Time (s)} \\
\midrule
eil51      & NN+2opt & 51  & 426    & 428    & 0.47  & 0.003 \\
           & ILP     & 51  & 426    & 426    & 0.00  & 0.033 \\
           & GA      & 51  & 426    & 432    & 1.41  & 0.154 \\
           & SA      & 51  & 426    & 511    & 19.95 & 0.060 \\
           & AMSH    & 51  & 426    & 427    & 0.23  & 0.490 \\
\midrule
berlin52   & NN+2opt & 52  & 7542   & 7542   & 0.00  & 0.007 \\
           & ILP     & 52  & 7542   & 7542   & 0.00  & 0.008 \\
           & GA      & 52  & 7542   & 7728   & 2.47  & 0.267 \\
           & SA      & 52  & 7542   & 8980   & 19.07 & 0.061 \\
           & AMSH    & 52  & 7542   & 7542   & 0.00  & 0.519 \\
\midrule
st70       & NN+2opt & 70  & 675    & 688    & 1.93  & 0.020 \\
           & GA      & 70  & 675    & 681    & 0.89  & 0.705 \\
           & SA      & 70  & 675    & 830    & 22.96 & 0.092 \\
           & AMSH    & 70  & 675    & 682    & 1.04  & 1.279 \\
\midrule
pr107      & NN+2opt & 107 & 44303  & 44600  & 0.67  & 0.018 \\
           & GA      & 107 & 44303  & 44834  & 1.20  & 2.796 \\
           & SA      & 107 & 44303  & 46680  & 5.37  & 0.139 \\
           & AMSH    & 107 & 44303  & 44600  & 0.67  & 4.153 \\
\midrule
ch130      & NN+2opt & 130 & 6110   & 6382   & 4.45  & 0.111 \\
           & GA      & 130 & 6110   & 6223   & 1.85  & 5.778 \\
           & SA      & 130 & 6110   & 7579   & 24.04 & 0.149 \\
           & AMSH    & 130 & 6110   & 6203   & 1.52  & 5.780 \\
\midrule
a280       & NN+2opt & 280 & 2579   & 2747   & 6.51  & 0.381 \\
           & GA      & 280 & 2579   & 2728   & 5.78  & 43.651 \\
           & SA      & 280 & 2579   & 3157   & 22.41 & 0.241 \\
           & AMSH    & 280 & 2579   & 2733   & 5.97  & 26.729 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Scalability trends.}
\begin{itemize}
\item \textbf{ILP infeasible beyond $n\approx 44$.} Gurobi's size-limited free license restricts variables to 2000; TSP ILP requires $n^2$ edge variables, so even eil51 ($51^2=2601$) exceeds the limit. For $n\le 44$, ILP remains the most reliable method, providing certified optimal solutions.
\item \textbf{NN+2opt: fast but degrading quality.} Gap increases from 0.47\% (eil51) to 6.51\% (a280), demonstrating that greedy construction plus local search is insufficient for larger instances. Runtime remains low ($<0.4$s for $n=280$), making NN+2opt an excellent warm-start generator.
\item \textbf{GA: robust across scales.} Gap ranges from 0.89\% (st70) to 5.78\% (a280), consistently outperforming NN+2opt on larger instances. Runtime scales polynomially ($O(n^2 \cdot \text{pop} \cdot \text{gen})$), reaching 43.7s for a280. The memetic integration (2-opt intensification) is crucial for solution quality.
\item \textbf{SA: consistently poor performance.} Gap remains in the range 19--24\% across all instances, indicating fundamental difficulty with the 2-opt neighborhood. Despite fast runtimes ($<0.25$s), SA's exploration-exploitation balance appears suboptimal for TSP. Alternative cooling schedules, reheating, or hybrid neighborhoods (e.g., 3-opt) may be necessary.
\item \textbf{AMSH: best heuristic solution quality.} AMSH achieves the lowest gaps among heuristics on 4/6 instances (eil51: 0.23\%, berlin52: 0.00\%, st70: 1.04\%, pr107: 0.67\%). Runtime is competitive with GA (both $O(n^2 \cdot I)$). The adaptive operator selection mechanism successfully identifies effective operators (typically 2-opt dominates in final weights), demonstrating the value of online learning in metaheuristic design.
\end{itemize}

\subsection{Discussion}
\paragraph{ILP vs. heuristics trade-off.}
For small instances ($n\le 44$ under free Gurobi license, or $n\le 100$ with full license), ILP with lazy SEC is the method of choice: it provides \emph{certified optimality} with competitive runtimes (0.008--0.033s for $n\approx 50$). Beyond ILP's feasibility range, heuristics are essential. Our results confirm that problem-specific metaheuristics (GA, AMSH) significantly outperform simple constructive heuristics (NN+2opt) on medium-to-large instances.

\paragraph{Why does SA fail?}
SA's poor performance (gap 19--24\%) despite extensive parameter tuning is surprising given its success in other domains. We hypothesize three factors: (1)~\emph{Neighborhood limitation}: the 2-opt neighborhood may be too restrictive for SA's single-solution trajectory, whereas population-based methods (GA) and multi-operator hybrids (AMSH) explore more diverse neighborhoods; (2)~\emph{Cooling schedule sensitivity}: geometric cooling may still be too aggressive for TSP's rugged landscape; adaptive or reheating schedules \cite{IngramBenjaafar2004} may help; (3)~\emph{Initialization quality}: while we use NN initialization, the inherent bias may trap SA in nearby local optima. Future work should investigate alternative SA designs, including hybrid neighborhoods (Or-opt, 3-opt) and population-based SA variants.

\paragraph{AMSH innovation and efficacy.}
AMSH's adaptive operator selection demonstrates clear benefits: on berlin52, AMSH matches the optimum (gap 0.00\%) while dynamically adjusting operator probabilities (typically converging to high weight for 2-opt, moderate for Or-opt/swap, low for 3-opt/insert). The online credit-assignment framework, inspired by ALNS \cite{Ropke2006ALNS}, enables automatic adaptation without manual parameter tuning. Compared to GA (fixed operators: crossover, mutation, memetic 2-opt), AMSH's flexibility allows it to allocate computational effort to the most productive operators for each instance. This is especially valuable in multi-instance scenarios where operator efficacy varies by problem structure. The overhead of pool management and weight updates is negligible ($<5\%$ of total runtime).

\paragraph{Practical recommendations.}
\begin{itemize}
\item For small instances ($n<50$): use ILP if feasible; otherwise NN+2opt as a fast heuristic.
\item For medium instances ($50\le n\le 200$): use AMSH or memetic GA; both achieve gaps $<2\%$ with runtimes $<10$s.
\item For large instances ($n>200$): AMSH recommended (best balance of quality and runtime); GA is competitive but slower.
\item Avoid vanilla SA for TSP unless augmented with hybrid neighborhoods or adaptive cooling.
\end{itemize}

\section{Conclusion}
We presented five Berlin52-executable methods spanning constructive heuristics (NN+2opt), exact optimization (ILP with lazy SEC), population-based metaheuristics (GA), single-solution metaheuristics (SA), and a novel adaptive hybrid (AMSH) that learns operator efficacy online. Each method is rigorously defined with complexity analysis and termination criteria. The experimental protocol compares solution quality, optimality gap, convergence behavior, and runtime against the known optimum 7542. AMSH represents a contribution in adaptive metaheuristic design by unifying multiple neighborhood operators under a credit-assignment framework, enabling automatic adaptation to problem structure. The complete Python implementation with Gurobi integration provides reproducible results and serves as a practical toolkit for TSP benchmarking. Future work includes extending AMSH to larger TSPLIB instances, investigating alternative credit-assignment strategies (e.g., multi-armed bandits), and transfer learning of operator weights across problem families.

\begin{thebibliography}{99}
\bibitem{GareyJohnson1979} M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to the Theory of NP-Completeness. W. H. Freeman, 1979.
\bibitem{Karp1972} R. M. Karp. Reducibility among combinatorial problems. In Complexity of Computer Computations, 1972.
\bibitem{Reinelt1995} G. Reinelt. TSPLIB—A traveling salesman problem library. ORSA Journal on Computing, 3(4):376–384, 1991. (TSPLIB95 updated online collection).
\bibitem{Applegate2006Concorde} D. L. Applegate, R. E. Bixby, V. Chvátal, and W. J. Cook. The Traveling Salesman Problem: A Computational Study. Princeton University Press, 2006. (See also the Concorde TSP Solver website.).
\bibitem{Gurobi} Gurobi Optimization, LLC. Gurobi Optimizer Reference Manual, 2024. https://www.gurobi.com.
\bibitem{HeldKarp1962} M. Held and R. M. Karp. A dynamic programming approach to sequencing problems. Journal of the Society for Industrial and Applied Mathematics, 10(1):196–210, 1962.
\bibitem{Bellman1962} R. Bellman. Dynamic programming treatment of the traveling salesman problem. Journal of the ACM, 9(1):61–63, 1962.
\bibitem{Flood1956} M. M. Flood. The traveling-salesman problem. Operations Research, 4(1):61–75, 1956.
\bibitem{Rosenkrantz1977} D. J. Rosenkrantz, R. E. Stearns, and P. M. Lewis. An analysis of several heuristics for the traveling salesman problem. SIAM Journal on Computing, 6(3):563–581, 1977.
\bibitem{Croes1958} G. A. Croes. A method for solving traveling-salesman problems. Operations Research, 6(6):791–812, 1958.
\bibitem{DFJ1954} G. B. Dantzig, R. Fulkerson, and S. Johnson. Solution of a large-scale traveling-salesman problem. Operations Research, 2(4):393–410, 1954.
\bibitem{PadbergRinaldi1991} M. W. Padberg and G. Rinaldi. A branch-and-cut algorithm for the resolution of large-scale symmetric traveling salesman problems. SIAM Review, 33(1):60–100, 1991.
\bibitem{MTZ1960} C. E. Miller, A. W. Tucker, and R. A. Zemlin. Integer programming formulation of traveling salesman problems. Journal of the ACM, 7(4):326–329, 1960.
\bibitem{Goldberg1989} D. E. Goldberg. Genetic Algorithms in Search, Optimization and Machine Learning. Addison-Wesley, 1989.
\bibitem{Davis1985} L. Davis. Applying adaptive algorithms to epistatic domains. IJCAI, 1985. (Introduces the order crossover operator.)
\bibitem{Michalewicz1996} Z. Michalewicz. Genetic Algorithms + Data Structures = Evolution Programs. Springer, 3rd ed., 1996.
\bibitem{Kirkpatrick1983} S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. Optimization by simulated annealing. Science, 220(4598):671–680, 1983.
\bibitem{Cerny1985} V. Černý. Thermodynamical approach to the traveling salesman problem: An efficient simulation algorithm. Journal of Optimization Theory and Applications, 45(1):41–51, 1985.
\bibitem{IngramBenjaafar2004} A. Ingram and S. Benjaafar. Adaptive reheating for simulated annealing. Computers \& Operations Research, 31(3):471–481, 2004.
\bibitem{Ropke2006ALNS} S. Ropke and D. Pisinger. An adaptive large neighborhood search heuristic for the pickup and delivery problem with time windows. Transportation Science, 40(4):455–472, 2006.
\end{thebibliography}

\end{document}
